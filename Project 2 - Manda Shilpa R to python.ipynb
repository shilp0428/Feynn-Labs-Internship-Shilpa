{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import msa\n",
    "mcdonalds = msa.datasets.load_mcdonalds()\n",
    "print(mcdonalds.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(mcdonalds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdonalds = pd.read_csv(\"mcdonalds.csv\")\n",
    "print(mcdonalds.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MD_x = np.array(mcdonalds.iloc[:, 0:11])\n",
    "MD_x = (MD_x == \"Yes\").astype(int)\n",
    "np.round(np.mean(MD_x, axis=0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "MD_pca = PCA().fit(MD_x)\n",
    "print(MD_pca.explained_variance_ratio_)\n",
    "print(MD_pca.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Assuming MD.pca is a matrix of data\n",
    "pca = PCA()\n",
    "pca.fit(MD.pca)\n",
    "\n",
    "# Print the results with one decimal place\n",
    "print(np.round(pca.components_, decimals=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# generate some data\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=5, random_state=42)\n",
    "\n",
    "# perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# plot the PCA results\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c='grey')\n",
    "\n",
    "# get the projection axes\n",
    "proj_axes = pca.components_\n",
    "\n",
    "print(proj_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# generate some data\n",
    "X, y = make_blobs(n_samples=100, centers=3, n_features=4, random_state=42)\n",
    "\n",
    "# perform k-medoids clustering using flexclust\n",
    "np.random.seed(1234)\n",
    "cluster_range = range(2, 9)\n",
    "best_model = None\n",
    "best_bic = np.inf\n",
    "\n",
    "for k in cluster_range:\n",
    "    for _ in range(10):\n",
    "        model = KMedoids(n_clusters=k, random_state=np.random.randint(1, 1000))\n",
    "        model.fit(X)\n",
    "        bic = model.inertia_\n",
    "        if bic < best_bic:\n",
    "            best_model = model\n",
    "            best_bic = bic\n",
    "\n",
    "# relabel the clusters\n",
    "cluster_labels = best_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate some data\n",
    "X, y = make_blobs(n_samples=100, centers=3, n_features=4, random_state=42)\n",
    "\n",
    "# perform k-medoids clustering using flexclust\n",
    "np.random.seed(1234)\n",
    "cluster_range = range(2, 9)\n",
    "bic_scores = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    for _ in range(10):\n",
    "        model = KMedoids(n_clusters=k, random_state=np.random.randint(1, 1000))\n",
    "        model.fit(X)\n",
    "        bic = model.inertia_\n",
    "        bic_scores.append((k, bic))\n",
    "\n",
    "# plot the results\n",
    "plt.plot([x[0] for x in bic_scores], [x[1] for x in bic_scores])\n",
    "plt.xlabel('number of segments')\n",
    "plt.ylabel('BIC score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# generate some data\n",
    "X, y = make_blobs(n_samples=100, centers=3, n_features=4, random_state=42)\n",
    "\n",
    "# perform bootstrapped k-medoids clustering using flexclust\n",
    "np.random.seed(1234)\n",
    "cluster_range = range(2, 9)\n",
    "boot_bic_scores = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    for _ in range(10):\n",
    "        k_bic_scores = []\n",
    "        for i in range(100):\n",
    "            X_resampled = resample(X, random_state=np.random.randint(1, 1000))\n",
    "            model = KMedoids(n_clusters=k, random_state=np.random.randint(1, 1000))\n",
    "            model.fit(X_resampled)\n",
    "            bic = model.inertia_\n",
    "            k_bic_scores.append(bic)\n",
    "        boot_bic_scores.append((k, np.mean(k_bic_scores)))\n",
    "\n",
    "# print the bootstrapped BIC scores\n",
    "print(boot_bic_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate some data\n",
    "X, y = make_blobs(n_samples=100, centers=3, n_features=4, random_state=42)\n",
    "\n",
    "# perform bootstrapped k-medoids clustering using flexclust\n",
    "np.random.seed(1234)\n",
    "cluster_range = range(2, 9)\n",
    "boot_bic_scores = []\n",
    "boot_ari_scores = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    for _ in range(10):\n",
    "        k_bic_scores = []\n",
    "        k_ari_scores = []\n",
    "        for i in range(100):\n",
    "            X_resampled = resample(X, random_state=np.random.randint(1, 1000))\n",
    "            model = KMedoids(n_clusters=k, random_state=np.random.randint(1, 1000))\n",
    "            model.fit(X_resampled)\n",
    "            bic = model.inertia_\n",
    "            k_bic_scores.append(bic)\n",
    "            ari = adjusted_rand_score(y, model.predict(X))\n",
    "            k_ari_scores.append(ari)\n",
    "        boot_bic_scores.append((k, np.mean(k_bic_scores)))\n",
    "        boot_ari_scores.append((k, np.mean(k_ari_scores)))\n",
    "\n",
    "# plot the results\n",
    "plt.plot([x[0] for x in boot_bic_scores], [x[1] for x in boot_ari_scores])\n",
    "plt.xlabel('number of segments')\n",
    "plt.ylabel('adjusted Rand index')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate some data\n",
    "X, y = make_blobs(n_samples=100, centers=4, n_features=4, random_state=42)\n",
    "\n",
    "# perform k-means clustering using flexclust\n",
    "model = KMeans(n_clusters=4, random_state=42)\n",
    "model.fit(X)\n",
    "\n",
    "# plot the histogram of cluster membership probabilities for the 4th cluster\n",
    "plt.hist(model.predict_proba(X)[:, 3], bins=10, range=(0, 1))\n",
    "plt.xlim((0, 1))\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that MD.km28 is already computed and contains the clustering results\n",
    "MD_k4 = MD_km28['4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "# assume that MD_x and MD_k4 are already computed\n",
    "# compute the dissimilarity matrix\n",
    "dissimilarity = euclidean_distances(MD_x)\n",
    "\n",
    "# perform metric scaling using multidimensional scaling (MDS)\n",
    "model = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "MD_r4 = model.fit_transform(dissimilarity[:, MD_k4 == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(MD_r4)), MD_r4[:, 1], c='b')\n",
    "plt.ylim((0, 1))\n",
    "plt.xlabel('Segment number')\n",
    "plt.ylabel('Segment stability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexmix import flexmix\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# assume that MD_x is already computed\n",
    "# scale the data\n",
    "MD_x_scaled = scale(MD_x)\n",
    "\n",
    "# perform model-based clustering using flexmix\n",
    "MD_m28 = flexmix(MD_x_scaled, k=range(2, 9), nrep=10, model='FLXMCmvbinary', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume that MD_m28 is already computed\n",
    "plt.plot(MD_m28.logLik)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Log-likelihood')\n",
    "plt.title('Model-based clustering results')\n",
    "plt.legend(['AIC', 'BIC', 'ICL'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that MD_m28, MD_k4 are already computed\n",
    "\n",
    "# get the model for 4 clusters\n",
    "MD_m4 = MD_m28.get_model(which=3)\n",
    "\n",
    "# compute the cross-tabulation of cluster assignments\n",
    "import pandas as pd\n",
    "pd.crosstab(index=clusters(MD_k4), columns=clusters(MD_m4), rownames=['KMeans'], colnames=['Mixture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fit a flexible mixture model with the KMeans clustering as the initial cluster assignments\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "import numpy as np\n",
    "\n",
    "# define a function to convert cluster assignments to binary indicators\n",
    "def get_indicators(clusters, num_clusters):\n",
    "    return np.eye(num_clusters)[clusters]\n",
    "\n",
    "# convert cluster assignments to binary indicators\n",
    "kmeans_indicators = get_indicators(clusters(MD_k4), 4)\n",
    "\n",
    "# fit the flexible mixture model\n",
    "MD_m4a = BayesianGaussianMixture(n_components=4, covariance_type='full', n_init=10, init_params='kmeans').fit(MD_x, kmeans_indicators)\n",
    "\n",
    "# compute the cross-tabulation of cluster assignments\n",
    "import pandas as pd\n",
    "pd.crosstab(index=clusters(MD_k4), columns=MD_m4a.predict(MD_x), rownames=['KMeans'], colnames=['Mixture'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
